## K-최근접 이웃(KNN)
- K-최근접 이웃은 거리 기반 모델입니다. 지금까지 다룬 알고리즘들과 달리 선형 관계를 전제로 하지 않습니다. 즉 각 데이터 간의 거리를 활용해서 새로운 데이터를 예측하는 모-  - 델입니다. 이때 가까이에 있는 데이터를 고려하여 예측값이 결정됩니다. K Nearest Neighbors라는 이름은 이를 잘 반영하고 있는데, K개의 가장 가까운 이웃 데이터에 의해 예측-  - 된다는 의미입니다.

- 구분 : 지도 학습
– 문제 유형 : 회귀/분류
– 적합한 데이터 유형 : 아웃라이어가 적은 데이터

![1](https://github.com/jaeb0129/baseball/assets/63768509/1587eeda-9d3f-45ad-9245-af625dca37b2)

- 장점

수식에 대한 설명이 필요 없을 만큼 직관적이고 간단합니다.
선형 모델과 다르게 별도의 가정이 없습니다(예를 들어 선형 회귀는 독립변수와 종속변수의 선형 관계를 가정하고 있기 때문에, 이 가정이 들어맞지 않는 데이터에 취약하나, KNN은 이러한 가정이 없어서 더 자유롭습니다).

- 단점

데이터가 커질수록 상당히 느려질 수 있습니다.
아웃라이어에 취약합니다.

- 유용한 곳

주로 분류(Classification)에서 사용되며, 로지스틱 회귀(Logistic Regression)로 해결할 수 없는 3개 이상의 목표 변수들도 분류할 수 있습니다.
작은 데이터셋에 적합합니다.

출처: https://goldenrabbit.co.kr/2022/07/14/%ED%99%95%EC%8B%A4%ED%9E%88-%EC%95%8C%EC%95%84%EB%91%90%EB%A9%B4-%EB%A7%8C%EC%82%AC%EA%B0%80-%ED%8E%B8%ED%95%B4%EC%A7%80%EB%8A%94-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-10%EA%B0%80%EC%A7%80-%EC%95%8C/
