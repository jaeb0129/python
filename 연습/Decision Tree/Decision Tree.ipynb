{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  target                   569 non-null    int32  \n",
      "dtypes: float64(30), int32(1)\n",
      "memory usage: 135.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유방암 진단 결정\n",
    "import sklearn.datasets as d\n",
    "import pandas as pd\n",
    "# breast_cancer 데이터 셋 로드\n",
    "x = d.load_breast_cancer()\n",
    "x\n",
    "cancer = pd.DataFrame(data = x.data, columns = x.feature_names)\n",
    "cancer.columns\n",
    "cancer['target'] = x.target\n",
    "\n",
    "cancer.info()\n",
    "cancer.describe()\n",
    "cancer.target.value_counts()\n",
    "# 총 569개 행, 31개 열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy:  1.0 \n",
      "\n",
      "Accuracy:  0.94 \n",
      "\n",
      "Recall:  0.96 \n",
      "\n",
      "Precision:  0.93 \n",
      "\n",
      "F1_score:  0.95 \n",
      "\n",
      "Confusion Matrix: \n",
      " [[62  7]\n",
      " [ 4 98]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.model_selection as ms\n",
    "\n",
    "# 트레인 데이터와 테스트 데이터 7:3 비율로 분할\n",
    "X = cancer.iloc[:,:-1]\n",
    "y = cancer.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, \n",
    "                                                      test_size = 0.3, random_state = 100)\n",
    "# DT 객체 생성 및 훈련\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train,y_train)\n",
    "\n",
    "# 예측값 저장\n",
    "y_pred = dt_clf.predict(X_test)\n",
    "\n",
    "import sklearn.metrics as mt\n",
    "\n",
    "# 학습결과 평가 \n",
    "\n",
    "print('Train_Accuracy: ', dt_clf.score(X_train, y_train),'\\n')\n",
    "\n",
    "accuracy = mt.accuracy_score(y_test, y_pred)\n",
    "recall = mt.recall_score(y_test, y_pred)\n",
    "precision = mt.precision_score(y_test, y_pred)\n",
    "f1_score = mt.f1_score(y_test, y_pred)\n",
    "matrix = mt.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Accuracy: ', format(accuracy,'.2f'),'\\n')\n",
    "print('Recall: ', format(recall,'.2f'),'\\n')\n",
    "print('Precision: ', format(precision,'.2f'),'\\n')\n",
    "print('F1_score: ', format(f1_score,'.2f'),'\\n')\n",
    "print('Confusion Matrix:','\\n', matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 현재 코드는 완벽하다고 할 수 없는데요, 바로 검증 데이터 셋을 나누지 않았기 때문입니다. 일정한 하나의 테스트셋으로 계속해서 평가를 진행하거나 하나의 트레인셋으로 학습을 진행하면 과적합이 쉽게 일어납니다. 그리고 일부 테스트셋에서만 좋은 성능을 보였다고 생각할 수 있기 때문에 검증방식을 바꿀 필요가 있습니다.\n",
    "\n",
    " 가장 많이 쓰는 방법은 ​K-Fold 교차검증(cross-validation)입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007529</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.912281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.912281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007571</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008399</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.956140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011151</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.884956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  0.007529    0.002025    0.912281\n",
       "1  0.008571    0.001991    0.912281\n",
       "2  0.007571    0.001992    0.921053\n",
       "3  0.008399    0.001958    0.956140\n",
       "4  0.011151    0.002995    0.884956"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 교차검증\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "# 각 폴드의 스코어 \n",
    "scores = cross_val_score(dt_clf, X, y, cv = 5)\n",
    "scores\n",
    "\n",
    "pd.DataFrame(cross_validate(dt_clf, X, y, cv =5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증 평균:  0.9156031672100605\n"
     ]
    }
   ],
   "source": [
    "print('교차검증 평균: ', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " K-fold를 통해 검증했을 때 각 테스트셋의 결과가 다르며 이것을 평균으로 냈을 때 91.3%정도로 기존보다 2% 떨어졌지만 다양한 테스트셋으로 검증했기 때문에 더 안전한 방식입니다. 그래서 우리가 스코어를 올리고자 하는 것은 검증 데이터의 평균 스코어와 최종 테스트셋의 스코어입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하이퍼 파라미터 튜닝(그리드 서치)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 모델 학습과정에서 꼭 필요한 파라미터 튜닝 작업입니다. 튜닝을 통해 모델의 과적합을 방지하고 모델 스코어를 올릴 수 있기 때문에 필수적인 작업입니다. 아래는 Decision Tree의 각 파라미터와 설명입니다. 이외에도 많은 파라미터가 있지만 주로 튜닝하는 파라미터만 준비했습니다. \n",
    "\n",
    "criterion : 이론 파트에서 다룬 노드 분리기준입니다. 'gini'와 'entropy'를 사용합니다.\n",
    "\n",
    "splitter : 노드 분리 방법으로 'random', 'best'를 사용합니다.\n",
    "\n",
    "max_depth : 트리 모형의 최대 깊이를 의미하며 값이 커질수록 깊어져 과적합이 쉽게 일어납니다.\n",
    "\n",
    "min_samples_split : 중간노드에서 분리가 일어나기 위한 샘플의 수입니다. \n",
    "\n",
    "min_samples_leaf : leaf 노드에서 필요한 최소한의 샘플 수이며 너무 적으면 과적합이 일어날 수 있습니다.\n",
    "\n",
    "max_features : 노드를 분리할 때 고려하는 속성의 수입니다. 'int', 'float', 'auto', 'sqrt', 'log2', None 값이 들어가며 각 다른 방식으로 계산해 속성의 수를 고려합니다.\n",
    "\n",
    "random_state : 다른 알고리즘에도 공통으로 들어가는 파라미터로 알고리즘은 실행마다 값이 변하기 때문에 값 변화를 보기 힘듭니다. 하지만 random_state를 고정하면 값 변화를 살펴보고 모델의 성능 개선에 대한 판단을 내릴 수 있습니다. \n",
    "\n",
    "​\n",
    "\n",
    " 아래 코드는 파라미터 튜닝을 하기위한 GridSearchCV입니다. sklearn 패키지에서 제공하는 것으로 튜닝하고 싶은 파라미터를 집어넣어 튜닝과 교차검증을 함께 진행할 수 있게 도와줍니다. gridsearch는 확인하고 싶은 다양한 파라미터값을 넣어주면 그것들을 하나씩 확인하면서 스코어를 내고 가장 좋은 성능의 모델에 대한 결과를 확인하고 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>splitter</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>random</td>\n",
       "      <td>0.932057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>random</td>\n",
       "      <td>0.929589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>random</td>\n",
       "      <td>0.929589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>random</td>\n",
       "      <td>0.922025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>0.919525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>0.919494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>best</td>\n",
       "      <td>0.919494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>0.917025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>best</td>\n",
       "      <td>0.916962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>random</td>\n",
       "      <td>0.909494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>random</td>\n",
       "      <td>0.909494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>best</td>\n",
       "      <td>0.906962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_samples_split splitter  mean_test_score\n",
       "5           5                  3   random         0.932057\n",
       "7           5                  5   random         0.929589\n",
       "9           7                  3   random         0.929589\n",
       "11          7                  5   random         0.922025\n",
       "4           5                  3     best         0.919525\n",
       "0           3                  3     best         0.919494\n",
       "2           3                  5     best         0.919494\n",
       "8           7                  3     best         0.917025\n",
       "6           5                  5     best         0.916962\n",
       "1           3                  3   random         0.909494\n",
       "3           3                  5   random         0.909494\n",
       "10          7                  5     best         0.906962"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 테스트하고자 하는 파라미터 값들을 사전타입으로 정의\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=33)\n",
    "parameters = {'max_depth': [3, 5, 7],\n",
    "              'min_samples_split': [3, 5],\n",
    "              'splitter': ['best', 'random']}\n",
    "\n",
    "grid_dt = GridSearchCV(dt_clf, # estimator 객체,\n",
    "                      param_grid = parameters, cv = 5,\n",
    "                      # n_jobs = -1: 모든 cpu를 사용)\n",
    "                      )\n",
    "\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "result = pd.DataFrame(grid_dt.cv_results_['params'])\n",
    "result['mean_test_score'] = grid_dt.cv_results_['mean_test_score']\n",
    "result.sort_values(by='mean_test_score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 결과에서 보면 알 수 있듯이 튜닝한 파라미터의 max_depth = 5, min_samples_split = 3, splitter = 'random' 일때 가장 좋은 성능을 보였습니다. mean_test_score는 각 fold 5개의 평균을 의미합니다. 튜닝전 92% -> 93%로 성능이 개선된 것을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각화\n",
    "\n",
    "## decision tree의 최대 장점 시각화와 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pydot_ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Users/jaeb0/anaconda3/Library/bin/graphviz/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import pydot_ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [5] ,\n",
    "              'min_samples_split': [3],\n",
    "              'splitter': ['random']}\n",
    "dt_clf = DecisionTreeClassifier(max_depth =5,\n",
    "              min_samples_split =  3,\n",
    "              splitter = 'random', random_state=33)\n",
    "\n",
    "\n",
    "best_dt = dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pydotplus.graphviz.Dot at 0x27add372730>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 의사결정트리 시각화를 위한 작업\n",
    "# 트리 시각화를 위한 export_graphviz 모듈 임포트 (이를 위해 graphviz 별도 설치 필요)\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus  # graphviz의 dot language 와의 인터페이스를 제공하는 패키지 임포트\n",
    "from IPython.display import Image  # IPython의 display와 관련된 Public API\n",
    "\n",
    "x_list = list(X.columns)\n",
    "y_list = list(y.drop_duplicates(inplace=False))\n",
    "\n",
    "# export_graphviz() : 의사결정트리에 대한 graphviz dot data를 생성하는 함수\n",
    "dot_data = export_graphviz(best_dt, out_file=None, feature_names=x_list,\n",
    "                          class_names=str(y_list), filled=True, rounded=True, special_characters=True)\n",
    "# matplotlib.rc('font', family='AppleGothic')\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  # graphviz의 dot data로부터 트리 그래프 생성\n",
    "graph\n",
    "# 트리 그래프를 위한 png 이미지 생성 및 출력\n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jaeb0\\\\Desktop\\\\graph.png'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(filename = 'graph', directory = 'C:/Users/jaeb0/Desktop', format = 'png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종 결과를 통해 각 클래스가 어떤 기준으로 선정되고 rule로 만들 수 있는 것이 Decision Tree의 가장 큰 장점입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}


# 출처: https://m.blog.naver.com/winddori2002/221659080425
